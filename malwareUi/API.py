import sys
import os
from math import log
import numpy as np
import scipy as sp
from PIL import Image
import matplotlib.pyplot as plt
from flask import request
from flask_cors import CORS
from distutils.log import debug
from flask import Flask, jsonify
import keras
import cv2
import sys
from tensorflow import keras
import tensorflow as tf
from keras.models import Sequential, Input, Model
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras.layers import BatchNormalization
from keras import Input
from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint
from keras.layers import Dense, Embedding, Conv1D, Conv2D, Multiply, GlobalMaxPooling1D, Dropout, Activation, RNN, LSTM, Bidirectional
from keras.layers import UpSampling2D, Flatten, merge, MaxPooling2D, MaxPooling1D, UpSampling1D, AveragePooling1D, GlobalMaxPooling2D
from keras.models import load_model, Model
from keras.layers import merge, Dropout, BatchNormalization, Maximum, Add, Lambda, Concatenate
from tensorflow.keras.optimizers import RMSprop
from sklearn.model_selection import train_test_split
from keras import backend as K
#from keras.engine.topology import Layer
from keras.utils.layer_utils import get_source_inputs
from sklearn.metrics import roc_auc_score, accuracy_score, log_loss, confusion_matrix, roc_curve, auc
import matplotlib.pyplot as plt

from keras.backend import set_session
import requests
from asyncio import tasks
import json 
import time 
import re
import hashlib
import logging
from sklearn.feature_extraction import FeatureHasher


app = Flask(__name__)
CORS(app)


def byte_to_image(readFromHere):
    print("called !!!")
    f = open(readFromHere)
    print("image has been read")
    array = []
    for line in f:
        xx = line.split()
        if len(xx) != 17:
            continue
        array.append([int(i, 16) if i != '??' else 0 for i in xx[1:]])
    f.close()
    array = np.array(array)
    if array.shape[1] != 16:
        assert(False)
    b = int((array.shape[0]*16)**(0.5))
    b = 2**(int(np.log(b)/np.log(2))+1)
    a = int(array.shape[0]*16/b)
    array = array[:a*b//16, :]
    array = np.reshape(array, (a, b))
    im = Image.fromarray(np.uint8(array))
    finalPath = "demo\\image1.png"
    im.save(finalPath, "PNG")
    return finalPath


def byte_to_markov_convertor(byte_file):
    freq = np.zeros((256, 256), dtype=float)
    with open(byte_file, 'r', encoding="utf-8") as file:
        p = file.read()
    temp = p.split("\n")
    final = []
    for item in temp:
        final.extend(item.split(" ")[1:])
    len_final = len(final)
    for i in range(len_final-1):
        if(final[i] != '??' and final[i+1] != '??'):
            freq[int(final[i], 16)][int(final[i+1], 16)] += 1
        else:
            pass

    # Laplacian Correction
    freq += 1e-6
    prob = freq/freq.sum(axis=1)[:, None]
    return prob

@app.route('/', methods=['GET', 'POST'])
def predict():
    ans = ""
    data = request.get_data()
    data = data.decode("utf-8")
    imgPath = data.replace('name=', '')
    passedIndex = imgPath[-1]
    imgPath = imgPath[:-1]
    passedIndex = int(passedIndex)
    print("here is the passed image", passedIndex)
    readFromHere = "demo/" + imgPath
    if passedIndex == 0:

        REST_URL = "http://localhost:8090/tasks/create/file"
        SAMPLE_FILE = imgPath

        HEADERS = {"Authorization": "Bearer UElEgVJvcQHWBoeslz0mAQ"}

        with open(SAMPLE_FILE, "rb") as sample:
            files = {"file": ("temp_file_name", sample)}
            r = requests.post(REST_URL, headers=HEADERS, files=files)



        task_id = r.json()["task_id"]
        #print(task_id)

        while(True):
            REST_URL = f"http://localhost:8090/tasks/report/{task_id}"
            r=requests.get(REST_URL, headers=HEADERS)
            if r.status_code==200:
                break
            time.sleep(30)
        if not os.path.isdir("json"):
            os.mkdir("json")
        os.system(f'curl -H "Authorization: Bearer UElEgVJvcQHWBoeslz0mAQ" http://localhost:8090/tasks/report/{task_id} >> json/{task_id}.json')


        class FeatureType(object):
            ''' Base class from which each feature type may inherit '''

            name = ''
            dim = 0

            def __repr__(self):
                return '{}({})'.format(self.name, self.dim)

            def raw_features(self, input_dict):
                ''' Generate a JSON-able representation of the file '''
                raise (NotImplemented)

            def process_features(self, raw_obj):
                ''' Generate a feature vector from the raw features '''
                raise (NotImplemented)

            def feature_vector(self, input_dict):
                ''' Directly calculate the feature vector from the sample itself. This should only be implemented differently
                if there are significant speedups to be gained from combining the two functions. '''
                return self.process_raw_features(self.raw_features(input_dict))


        class APIName(FeatureType):
            ''' api_name hash info '''

            name = 'api_name'
            dim = 8

            def __init__(self):
                super(FeatureType, self).__init__()
                self._name = re.compile('^[a-z]+|[A-Z][^A-Z]*')

            def raw_features(self, input_dict):
                """
                input_dict: string
                """
                tmp = self._name.findall(input_dict)
                hasher = FeatureHasher(self.dim, input_type="string").transform([tmp]).toarray()[0]
                return hasher

            def process_raw_features(self, raw_obj):
                return raw_obj


        class APICategory(FeatureType):
            ''' api_category hash info '''
            
            name = 'api_category'
            dim = 4

            def __init__(self):
                super(FeatureType, self).__init__()

            def raw_features(self, input_dict):
                hasher = FeatureHasher(self.dim, input_type="string").transform([input_dict]).toarray()[0]
                return hasher

            def process_raw_features(self, raw_obj):
                return raw_obj


        class IntInfo(FeatureType):
            ''' int hash info '''

            name = 'int'
            dim = 16

            def __init__(self):
                super(FeatureType, self).__init__()

            def raw_features(self, input_dict):
                hasher = FeatureHasher(self.dim).transform([input_dict]).toarray()[0]
                return hasher

            def process_raw_features(self, raw_obj):
                return raw_obj


        class PRUIInfo(FeatureType):
            ''' Path, Registry, Urls, IPs hash info '''

            name = 'prui'
            dim = 16 + 8 + 12 + 16 + 12

            def __init__(self):
                super(FeatureType, self).__init__()
                self._paths = re.compile('^c:\\\\', re.IGNORECASE)
                self._dlls = re.compile('.+\.dll$', re.IGNORECASE)
                self._urls = re.compile('^https?://(.+?)[/|\s|:]', re.IGNORECASE)
                self._registry = re.compile('^HKEY_')
                self._ips = re.compile('^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}')

            def raw_features(self, input_dict):
                paths = np.zeros((16,), dtype=np.float32)
                dlls = np.zeros((8,), dtype=np.float32)
                registry = np.zeros((12,), dtype=np.float32)
                urls = np.zeros((16,), dtype=np.float32)
                ips = np.zeros((12,), dtype=np.float32)
                for str_name, str_value in input_dict.items():
                    if self._dlls.match(str_value):
                        tmp = re.split('//|\\\\|\.', str_value)[:-1]
                        tmp = ['\\'.join(tmp[:i]) for i in range(1, len(tmp) + 1)]
                        dlls += FeatureHasher(8, input_type="string").transform([tmp]).toarray()[0]
                    if self._paths.match(str_value):
                        tmp = re.split('//|\\\\|\.', str_value)[:-1]
                        tmp = ['\\'.join(tmp[:i]) for i in range(1, len(tmp) + 1)]
                        paths += FeatureHasher(16, input_type="string").transform([tmp]).toarray()[0]
                    elif self._registry.match(str_value):
                        tmp = str_value.split('\\')[:6]
                        tmp = ['\\'.join(tmp[:i]) for i in range(1, len(tmp) + 1)]
                        registry += FeatureHasher(12, input_type="string").transform([tmp]).toarray()[0]
                    elif self._urls.match(str_value):
                        tmp = self._urls.split(str_value + "/")[1]
                        tmp = tmp.split('.')[::-1]
                        tmp = ['.'.join(tmp[:i][::-1]) for i in range(1, len(tmp) + 1)]
                        urls += FeatureHasher(16, input_type="string").transform([tmp]).toarray()[0]
                    elif self._ips.match(str_value):
                        tmp = str_value.split('.')
                        tmp = ['.'.join(tmp[:i]) for i in range(1, len(tmp) + 1)]
                        ips += FeatureHasher(12, input_type="string").transform([tmp]).toarray()[0]
                return np.hstack([paths, dlls, registry, urls, ips]).astype(np.float32)

            def process_raw_features(self, raw_obj):
                return raw_obj


        class StringsInfo(FeatureType):
            ''' Other printable strings hash info '''

            name = 'strings'
            dim = 8

            def __init__(self):
                super(FeatureType, self).__init__()
                self._allstrings = re.compile(b'[\x20-\x7f]{5,}')
                self._paths = re.compile(b'c:\\\\', re.IGNORECASE)
                self._dlls = re.compile(b'\\.dll', re.IGNORECASE)
                self._urls = re.compile(b'https?://', re.IGNORECASE)
                self._registry = re.compile(b'HKEY_')
                self._mz = re.compile(b'MZ')
                self._ips = re.compile(b'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}')
                super(FeatureType, self).__init__()

            def raw_features(self, input_dict):
                bytez = '\x11'.join(input_dict.values()).encode('UTF-8', 'ignore')
                allstrings = self._allstrings.findall(bytez)
                if allstrings:
                    # statistics about strings:
                    string_lengths = [len(s) for s in allstrings]
                    avlength = sum(string_lengths) / len(string_lengths)
                    # map printable characters 0x20 - 0x7f to an int array consisting of 0-95, inclusive
                    as_shifted_string = [b - ord(b'\x20') for b in b''.join(allstrings)]
                    c = np.bincount(as_shifted_string, minlength=96)  # histogram count
                    # distribution of characters in printable strings
                    csum = c.sum()
                    p = c.astype(np.float32) / csum
                    wh = np.where(c)[0]
                    H = np.sum(-p[wh] * np.log2(p[wh]))  # entropy
                else:
                    avlength = 0
                    c = np.zeros((96,), dtype=np.float32)
                    H = 0
                    csum = 0
                return {
                    'numstrings': len(allstrings),
                    'avlength': avlength,
                    'printables': int(csum),
                    'entropy': float(H),
                    'paths': len(self._paths.findall(bytez)),
                    'dlls': len(self._dlls.findall(bytez)),
                    'urls': len(self._urls.findall(bytez)),
                    'registry': len(self._registry.findall(bytez)),
                    'ips': len(self._ips.findall(bytez)),
                    'MZ': len(self._mz.findall(bytez))
                }

            def process_raw_features(self, raw_obj):
                return np.hstack([
                    raw_obj['numstrings'], raw_obj['avlength'], raw_obj['printables'],
                    raw_obj['entropy'], raw_obj['paths'], raw_obj['dlls'], raw_obj['urls'],
                    raw_obj['registry'], raw_obj['ips'], raw_obj['MZ']
                ]).astype(np.float32)


        class DMDS(object):

            def __init__(self, file_name, input_path, output_path, max_len, idx):
                logging.info('Generating vector for task %s' % idx)

                self.idx = idx
                self.behaviour_report = None
                self.nrdma_output = None
                self.max_len = max_len
                self.features = dict((fe.name, fe) for fe in
                                    [APIName(), APICategory(), IntInfo(), PRUIInfo(), StringsInfo()])
                self.input_path = input_path
                self.output_path = output_path
                self.file_name = file_name
                self.infile = self.input_path.format(self.file_name)
                self.outfile = self.output_path.format(self.file_name)

            def parse(self):
                if not os.path.exists(self.infile):
                    logging.warning("Behaviour report does not exist.")
                    return False
                if os.path.exists(self.outfile):
                    logging.warning("Behaviour report already parsed.")
                    return False
                try:
                    json_data = open(self.infile, "r")
                    self.behaviour_report = json.load(json_data)
                    return True
                except Exception as e:
                    logging.error('Could not parse the behaviour report. {%s}' % e)
                    return False

            def write(self):
                outputfile = self.output_path.format(self.file_name)
                logging.info("Writing task %s report to: %s" % (self.idx, outputfile))
                np.save(outputfile, self.nrdma_output)
                return True

            def add_to_output(self, sample):
                if self.nrdma_output is None:
                    self.nrdma_output = [sample]
                else:
                    self.nrdma_output = np.append(self.nrdma_output, [sample], axis=0)
                return len(self.nrdma_output)

            def convert_thread(self, pid, tid, api_calls):
                previous_hashed = ""
                for call in api_calls:
                    if self.nrdma_output is not None and len(self.nrdma_output) >= self.max_len:
                        return True
                    if 'api' not in call:
                        continue
                    if call['api'][:2] == '__':
                        continue
                    if 'arguments' not in call:
                        call['arguments'] = {}
                    if 'category' not in call:
                        call['category'] = ""
                    if 'status' not in call:
                        call['status'] = 0
                    arguments = call['arguments']
                    category = call['category']
                    api = call['api']
                    call_sign = api + "-" + str(arguments)
                    current_hashed = hashlib.md5(call_sign.encode()).hexdigest()
                    if previous_hashed == current_hashed:
                        continue
                    else:
                        previous_hashed = current_hashed
                    api_name_hashed = self.features['api_name'].feature_vector(api)
                    api_category_hashed = self.features['api_category'].feature_vector(
                        category)
                    api_int_dict, api_str_dict = {}, {}
                    for c_n, c_v in arguments.items():
                        if isinstance(c_v, (list, dict, tuple)):
                            continue
                        if isinstance(c_v, (int, float)):
                            api_int_dict[c_n] = np.log(np.abs(c_v) + 1)
                        else:
                            if c_v[:2] == '0x':
                                continue
                            api_str_dict[c_n] = c_v
                    try:
                        api_int_hashed = self.features['int'].feature_vector(api_int_dict)
                        api_prui_hashed = self.features['prui'].feature_vector(
                            api_str_dict)
                        api_str_hashed = self.features['strings'].feature_vector(
                            api_str_dict)
                        hashed_feature = np.hstack(
                            [api_name_hashed, api_category_hashed, api_int_hashed, api_prui_hashed, api_str_hashed]).astype(
                            np.float32)
                        self.add_to_output(hashed_feature)
                    except Exception as e:
                        logging.error("Task %s error: %s" % (self.idx, e))
                        pass

                return True

            #  Launch the conversion on all threads in the JSON
            def convert(self):
                processes = {}
                try:
                    procs = self.behaviour_report['behavior']['processes']
                    for proc in procs:
                        process_id = proc['pid']
                        parent_id = proc['ppid']
                        process_name = proc['process_name']
                        calls = proc['calls']
                        #  Create a dictionnary of threads
                        # The key is the n° of the thread
                        # The content is all calls he makes
                        threads = {}
                        for call in calls:
                            thread_id = call['tid']
                            try:
                                threads[thread_id].append(call)
                            except:
                                threads[thread_id] = []
                                threads[thread_id].append(call)

                        # Create a dictionnary of process
                        # The key is the id of the process
                        processes[process_id] = {}
                        processes[process_id]["parent_id"] = parent_id
                        processes[process_id]["process_name"] = process_name
                        processes[process_id]["threads"] = threads
                except Exception as e:
                    logging.error("Task %s error: %s" % (self.idx, e))
                # For all processes...
                for p_id in processes:
                    #  For each threads of those processes...
                    for t_id in processes[p_id]["threads"]:
                        # Convert the thread
                        self.convert_thread(p_id, t_id, processes[p_id]["threads"][t_id])
                return True

        file_name = '0FA68B45B3BFEEF29D14A8E5965F27A979A66A2E47AB9F5A896E651685906F92_388623_0'
        input_path = f"json/{task_id}.json"
        output_path = f"npy/{task_id}.npy"
        dmds = DMDS(file_name, input_path, output_path, 1000, 40)
        if dmds.parse() and dmds.convert():
            dmds.write()

        
        import tensorflow.compat.v1 as tf
        tf.disable_v2_behavior()
        # # os.environ["CUDA_VISIBLE_DEVICES"] = "0"

        # config = tf.ConfigProto()
        # config.gpu_options.allow_growth = True
        # set_session(tf.Session(config=config))

        Model = keras.models.load_model("cnn_lstm_model_best.hdf5")
        dim = 1000
        X = np.zeros((1, dim, 102), dtype=float)
        tmp = np.load(f'npy/{task_id}.npy')
        tmp = np.clip(tmp, -100, 100)
        if tmp.shape[0] < dim:
            X[0, :tmp.shape[0], :] = tmp
        else :
            X[0] = tmp[:dim, :]
        
        y_pred = Model.predict(X)
        label = (y_pred > 0.5).astype(int)
        if label==0:
            ans="Benign"
        else:
            ans="Malicious"


    elif passedIndex == 1:
        label_to_index_dict = {'Adialer.C': 0, 'Agent.FYI': 1, 'Allaple.A': 2, 'Allaple.L': 3, 'Alueron.gen!J': 4, 'Autorun.K': 5, 'C2LOP.P': 6, 'C2LOP.gen!g': 7, 'Dialplatform.B': 8, 'Dontovo.A': 9, 'Fakerean': 10, 'Instantaccess': 11,
                               'Lolyda.AA1': 12, 'Lolyda.AA2': 13, 'Lolyda.AA3': 14, 'Lolyda.AT': 15, 'Malex.gen!J': 16, 'Obfuscator.AD': 17, 'Rbot!gen': 18, 'Skintrim.N': 19, 'Swizzor.gen!E': 20, 'Swizzor.gen!I': 21, 'VB.AT': 22, 'Wintrim.BX': 23, 'Yuner.A': 24}
        index_to_label_dict = {0: 'Adialer.C', 1: 'Agent.FYI', 2: 'Allaple.A', 3: 'Allaple.L', 4: 'Alueron.gen!J', 5: 'Autorun.K', 6: 'C2LOP.P', 7: 'C2LOP.gen!g', 8: 'Dialplatform.B', 9: 'Dontovo.A', 10: 'Fakerean', 11: 'Instantaccess',
                               12: 'Lolyda.AA1', 13: 'Lolyda.AA2', 14: 'Lolyda.AA3', 15: 'Lolyda.AT', 16: 'Malex.gen!J', 17: 'Obfuscator.AD', 18: 'Rbot!gen', 19: 'Skintrim.N', 20: 'Swizzor.gen!E', 21: 'Swizzor.gen!I', 22: 'VB.AT', 23: 'Wintrim.BX', 24: 'Yuner.A'}
        markov = byte_to_markov_convertor(readFromHere)
        plt.plot(markov)
        # plt.savefig("demo\\image1.png")
        markov = np.expand_dims(markov, 0)
        Markov_model = keras.models.load_model('cnn_on_malimg_markov.hdf5')
        y_pred = Markov_model.predict(markov, verbose=0)
        y_pred_labels = np.argmax(y_pred, axis=1)
        ans += index_to_label_dict[y_pred_labels[0]]
        print("i am in the index 1 and the ans is", ans)
    else:
        ans+='index2'
    return ans


if __name__ == "__main__":
    app.run(debug=True)
